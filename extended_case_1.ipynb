{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-baec21b6430a0b5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# How can we control the increasing number of accidents in New York?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25c879fc483dae29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import base64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c8cd80e3119bd3da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "**Business Context.** The city of New York has seen a rise in the number of accidents on the roads in the city. They would like to know if the number of accidents have increased in the last few weeks. For all the reported accidents, they have collected details for each accident and have been maintaining records for the past year and a half (from January 2018 to August 2019). \n",
    "\n",
    "The city has contracted you to build visualizations that would help them identify patterns in accidents, which would help them take preventive actions to reduce the number of accidents in the future. They have certain parameters like borough, time of day, reason for accident, etc. Which they care about and which they would like to get specific information on.\n",
    "\n",
    "**Business Problem.** Your task is to format the given data and provide visualizations that would answer the specific questions the client has, which are mentioned below.\n",
    "\n",
    "**Analytical Context.** You are given a CSV file (stored in the already created ```data``` folder) containing details about each accident like date, time, location of the accident, reason for the accident, types of vehicles involved, injury and death count, etc. The delimiter in the given CSV file is `;` instead of the default `,`. You will be performing the following tasks on the data:\n",
    "\n",
    "1. Extract additional borough data stored in a JSON file\n",
    "2. Read, transform, and prepare data for visualization\n",
    "3. Perform analytics and construct visualizations of the data to identify patterns in the dataset\n",
    "        \n",
    "The client has a specific set of questions they would like to get answers to. You will need to provide visualizations to accompany these:\n",
    "\n",
    "1. How have the number of accidents fluctuated over the past year and a half? Have they increased over the time?\n",
    "2. For any particular day, during which hours are accidents most likely to occur?\n",
    "3. Are there more accidents on weekdays than weekends?\n",
    "4. What are the accidents count-to-area ratio per borough? Which boroughs have disproportionately large numbers of accidents for their size?\n",
    "5. For each borough, during which hours are accidents most likely to occur?\n",
    "6. What are the top 5 causes of accidents in the city? \n",
    "7. What types of vehicles are most involved in accidents per borough?\n",
    "8. What types of vehicles are most involved in deaths?\n",
    "\n",
    "**Note:** To solve this extended case, please read the function docstrings **very carefully**. They contain information that you will need! Also, please don't include `print()` statements inside your functions (they will most likely produce an error in the test cells)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70d08a0bd2b05b7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Fetching the relevant data\n",
    "\n",
    "The client has requested analysis of the accidents-to-area ratio for boroughs. Borough data is stored in a JSON file in the ```data``` folder (this file was created using data from [Wikipedia](https://en.wikipedia.org/wiki/Boroughs_of_New_York_City))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-03024018922a920e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Question\n",
    "\n",
    "Use the function ```json.load()``` to load the file ```borough_data.json``` as a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f9d16d6ed3e0570f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92d2a3461441cf8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('data/borough_data.json') as f:\n",
    "    borough_data=json.load(f)\n",
    "borough_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8726ed13ca1fc4b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "5_min"
    ]
   },
   "source": [
    "### Question\n",
    "\n",
    "Similarly, use the `pandas` function ```read_csv()``` to load the file ```accidents.csv``` as a DataFrame. Name this DataFrame ```df```. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6c149306cdaba5e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Answer.** One possible solution is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-452bccc1dd49b599",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('data/accidents.csv') as f:\n",
    "    df=pd.read_csv(f, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bb4232cd61a3b75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Overview of the data\n",
    "\n",
    "Let's go through the columns present in the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b3d44ba2d19eaf68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9ea9fcbd9ca91b67",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We have the following columns:\n",
    "\n",
    "1. **BOROUGH**: The borough in which the accident occurred\n",
    "2. **COLLISION_ID**: A unique identifier for this collision\n",
    "3. **CONTRIBUTING FACTOR VEHICLE (1, 2, 3, 4, 5)**: Reasons for the accident\n",
    "4. **CROSS STREET NAME**: Nearest cross street to the location of the accident\n",
    "5. **DATE**: Date of the accident\n",
    "6. **TIME**: Time of the accident\n",
    "7. **LATITUDE**: Latitude of the accident\n",
    "8. **LONGITUDE**: Longitude of the accident\n",
    "9. **NUMBER OF (CYCLISTS, MOTORISTS, PEDESTRIANS) INJURED**: Injuries by category\n",
    "10. **NUMBER OF (CYCLISTS, MOTORISTS, PEDESTRIANS) KILLED**: Deaths by category\n",
    "11. **ON STREET NAME**: Street where the accident occurred\n",
    "13. **VEHICLE TYPE CODE (1, 2, 3, 4, 5)**: Types of vehicles involved in the accident\n",
    "14. **ZIP CODE**: Zip code of the accident location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-37d76b97293b8df9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "Since 2014, New York City has been implementing a road safety plan named [Vision Zero](https://www1.nyc.gov/content/visionzero/pages/). It aims to reduce the number of traffic deaths to *zero* by the end of 2024. The plan is creating new and enhancing current safety measures, some of these include:\n",
    "\n",
    "<ul>\n",
    "A. Automated pedestrian detection<br>\n",
    "B. Road safety audits at high risk locations<br>\n",
    "C. Expansion in the cycle track network<br>\n",
    "D. Targeted education and awareness initiatives<br>\n",
    "E. Creation of pedestrian refuge islands<br>\n",
    "F. Launch Integrated Data-Driven Speed Reducer Program (speed humps & speed cushions)<br>\n",
    "</ul>\n",
    "\n",
    "Which of these initiatives could directly benefit from an analysis of the data provided?\n",
    "\n",
    "**Note:** In this notebook, whenever you are asked to write text, use the cell below the question cell to write your answer there. If you write in the same cell as the question, your answer will not be recorded.\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.** B, D, and F.\n",
    "\n",
    "- Automated pedestrian detection: NO\n",
    "\n",
    "The data provided contains the exact location, the number of pedestrians injured/killed, and the contributing factor of the vehicles in each accident. We could study the accidents where pedestrians were injured or killed. This *could* help to place cameras at important spots, where the automatic detection may be needed. However, for the *implementation* of automated pedestrian detection, a data set of images of crosswalks and intersections is more crucial.\n",
    "\n",
    "- Road safety audits at high risk locations: YES\n",
    "\n",
    "As discussed, our data can help with the recognition of problematic spots. We can check the street names where a high number of accidents have occurred in the past, then inspect the area to see what extra measures should be implemented. \n",
    "\n",
    "- Expansion in the cycle track network: NO\n",
    "\n",
    "Our data contains the number of cyclists injured/killed. We could determine the spots where these are happening the most and then improve the safety measures around the area. However, we would need more data to determine if these locations have a high volume of cyclists. Thus the data may not be that beneficial for making decisions on expanding the cycle network.\n",
    "\n",
    "- Targeted education and awareness initiatives: YES\n",
    "\n",
    "The data provides the contributing factor of the accidents along with the type of vehicles that were involved in them. We can then study which types of vehicles cause the most number of accidents and organize educational initiatives around this.\n",
    "\n",
    "- Creation of pedestrian refuge islands: NO\n",
    "\n",
    "Pedestrian islands are usually created on streets that are very wide. Thus, the information provided might not be that beneficial for this initiative, as we do not have information on the width/size of streets.\n",
    "\n",
    "- Launch Integrated Data-Driven Speed Reducer Program (speed humps & speed cushions): YES\n",
    "\n",
    "One of the contributing factors in accidents provided in the data is speeding. We can check if these accidents occur in highly transited areas. Thus, our data might be useful for the implementation of this initiative.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-322e46a25360428f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Answering the client's questions\n",
    "\n",
    "Let's go ahead and answer each of the client's questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27abb76445cf702f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "#### 2.1\n",
    "\n",
    "Group the available accident data by month.\n",
    "\n",
    "**Hint**: You may find the `pandas` functions [```pd.to_datetime()```](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) and [```dt.to_period()```](https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.to_period.html) useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f972809ebfaaa5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_2(df):\n",
    "    \"\"\"\n",
    "    Group accidents by month\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame\n",
    "    \n",
    "    Outputs:\n",
    "    `monthly_accidents`: The grouped Series\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    #First we need to change the format of the column DATE to datetime:\n",
    "    df['DATE']=pd.to_datetime(df['DATE'])\n",
    "\n",
    "    #Then, check whether the number of accidents has increased over time\n",
    "    monthly_accidents = df.groupby(df['DATE'].dt.to_period('M')).size()\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return monthly_accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bad4418558ffdda1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.2\n",
    "##### 2.2.1\n",
    "\n",
    "Generate a line plot of accidents over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6d7a0247f12984b9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_2(df).plot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d540425a1eb372c9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 2.2.2\n",
    "\n",
    "Has the number of accidents increased over the past year and a half?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> The line graph clearly shows that there is no obvious uptrend in accidents over time.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cae82d4401d36c90",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "From the plot above, which months seem to have the least number of accidents? What do you think are the reasons behind this?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.** You get full points if you noticed at least one of the following (otherwise, nothing):\n",
    "\n",
    "* August of 2019 is the month with the lowest number of accidents (this is is probably due to the fact that there is not a complete record for this month, since the latest record in August is from the 24th, namely, the entire final week of data is missing).\n",
    "\n",
    "* Disregarding this month, the lowest number of accidents appear to happen in February. This is the month of the year with the lowest temperatures and road conditions might get a little complicated. Thus, people may prefer to use public transportation and avoid going out as much as possible due to the cold weather. This is in contrast with summer, where people are prone to go out and more accidents may occur.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a56ec753bfddd1f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 4\n",
    "\n",
    "#### 4.1\n",
    "\n",
    "Create a new column `HOUR` based on the data from the `TIME` column.\n",
    "\n",
    "**Hint:** You may find the ```dt.hour``` accessor useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-419c27e92f4c8976",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_4(df):\n",
    "    \"\"\"\n",
    "    Group accidents by hour of day\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame\n",
    "    \n",
    "    Outputs:\n",
    "    `hourly_accidents`: The grouped Series\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # First change the format of the TIME column\n",
    "    df['TIME']=pd.to_datetime(df['TIME'])\n",
    "\n",
    "    # Create a new hour column \n",
    "    df['HOUR'] = df['TIME'].dt.hour\n",
    "\n",
    "    # Find out how the number of accidents varies across hours. \n",
    "    hourly_accidents = df.groupby('HOUR').size()\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return hourly_accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f0cd15b77d1d9c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 4.2\n",
    "##### 4.2.1\n",
    " \n",
    "Plot a bar graph of the distribution per hour throughout the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-afd6b1b063e2f80e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_4(df).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d76634ab8ea839d4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 4.2.2\n",
    "How does the number of accidents vary throughout a single day?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> From this, we see that more accidents occur in the afternoon (2 - 6 PM) than at other times of day.\n",
    "\n",
    "=== END MARK SCHEME ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcc6952bd1f46a1c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "In the above question we have aggregated the number accidents per hour disregarding the date and place of occurrence. What criticism would you give to this approach?\n",
    "\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.** You get half points if you mentioned one of these and full points if you mentioned both:\n",
    "\n",
    "* Aggregating the data will be a problem if the disregarded variables exhibit large degrees of variation and are not distributed very evenly. It may be the case that the concentration of accidents in some zones of the city happen at different times of the day, yet by aggregating the data we may falsely conclude that accidents are constant in the entire city.\n",
    "* Probably, residential zones are busy around 5 - 7pm, but commercial or manufaturing zones might be busy around 3 - 5pm. This information is important if the client is interested in designing a deployment plan for police officers to litigate traffic accidents, yet will be missed if we aggregate across all places of occurrence.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-456b65bd1173ae5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "15_min"
    ]
   },
   "source": [
    "### Exercise 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-40afb0de48f6e2fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 6.1\n",
    "\n",
    "Calculate the number of accidents by day of the week.\n",
    "\n",
    "**Hint:** You may find the ```dt.weekday``` accessor useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-293c8b93b1f61fac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_6(df):\n",
    "    \"\"\"\n",
    "    Group accidents by day of the week\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame\n",
    "    \n",
    "    Outputs:\n",
    "    `weekday_accidents`: The grouped Series\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # First change the format of the DATE column\n",
    "    df['DATE']=pd.to_datetime(df['DATE'])\n",
    "    \n",
    "    # Extract the weekday\n",
    "    df['WEEKDAY'] = df['DATE'].dt.weekday\n",
    "    \n",
    "    # Grouping\n",
    "    weekday_accidents = df.groupby('WEEKDAY').size()\n",
    "        \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return weekday_accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29d747391521c660",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 6.2\n",
    "##### 6.2.1\n",
    "Plot a bar graph based on the accidents count by day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b4465bdaadd4a0ba",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_6(df).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-540dd79f4dc3dd25",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 6.2.2\n",
    "\n",
    "How does the number of accidents vary throughout a single week?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> There are relatively fewer accidents on weekends than weekdays.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da89c04d5c6f9ab1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "30_min"
    ]
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "#### 7.1\n",
    "\n",
    "Calculate the total number of accidents for each borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ba5491dce624e79",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_7_1(df):\n",
    "    \"\"\"\n",
    "    Group accidents by borough\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame\n",
    "    \n",
    "    Outputs:\n",
    "    `boroughs`: The grouped Series\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    boroughs = df.groupby('BOROUGH').size()\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return boroughs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcb020d87a3bc3a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 7.2\n",
    "##### 7.2.1\n",
    "\n",
    "Plot a bar graph of the previous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ebdddab103414bb4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_7_1(df).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20a42e3df9860ed7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 7.2.2\n",
    "\n",
    "What do you notice in the plot?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> We can see that Brooklyn and Queens have a very high number of accidents relative to the other three boroughs.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ec1ee4f915e4f7d5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 7.3 (hard)\n",
    "\n",
    "How about per square mile? Calculate the number accidents per square mile for each borough.\n",
    "\n",
    "**Hint:** You will have to update the keys in the borough dictionary to match the names in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6739c46c019dfd0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_7_3(df, borough_data):\n",
    "    \"\"\"\n",
    "    Calculate accidents per sq mile for each borough\n",
    "    \n",
    "    Arguments:\n",
    "    `borough_frame`: A pandas DataFrame with the count of accidents per borough\n",
    "    `borough_data`: A python dictionary with population and area data for each borough\n",
    "    \n",
    "    \n",
    "    Outputs:\n",
    "    `borough_frame`: The same `borough_frame` DataFrame used as input, only with an\n",
    "    additional column called `accidents_per_sq_mi` that results from dividing\n",
    "    the number of accidents in each borough by its area. Please call this new column\n",
    "    exactly `accidents_per_sq_mi` - otherwise the test cells will throw an error.\n",
    "    \"\"\"\n",
    "    \n",
    "    boroughs = ex_7_1(df)\n",
    "    borough_frame = pd.DataFrame(boroughs)\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    # Since there are differences in the text used in the data and Wikipedia data, let's update it\n",
    "    borough_data['bronx'] = borough_data.pop('the bronx')    \n",
    "    \n",
    "    # Making the keys in borough_frame lowercase\n",
    "    borough_frame.columns = ['count']\n",
    "    borough_frame['borough'] = borough_frame.index.str.lower()\n",
    "    \n",
    "    # Calculating accidents per square mile\n",
    "    borough_frame['accidents_per_sq_mi'] = borough_frame.apply(lambda x: x['count'] / borough_data[x['borough']]['area'], axis=1)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return borough_frame # This must be a DataFrame, NOT a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ce964972da9e2c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 7.4\n",
    "##### 7.4.1\n",
    "\n",
    "Plot a bar graph of the accidents per square mile per borough with the data you just calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-35a7dba3a934592f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_7_3(df, borough_data).plot.bar(x='borough', y='accidents_per_sq_mi', legend=False, title=\"Accidents per sq mi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52f66926e9de15b1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 7.4.2\n",
    "\n",
    "What can you conclude?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> When looking at the `accidents_per_sq_mi` parameter, Manhattan tops the list by a wide margin. This clearly shows that even though Brooklyn and Queens have more total accidents, Manhattan has a much higher concentration of accidents.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-614c2ca6ab488cb3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "20_min"
    ]
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "#### 8.1\n",
    "\n",
    "Create a Series of the number of accidents per hour and borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-27af814f24d2deba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_8_1(df):\n",
    "    \"\"\"\n",
    "    Calculate accidents per hour for each borough\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame\n",
    "    \n",
    "    \n",
    "    Outputs:\n",
    "    `bor_hour`: A Series. This should be the result of doing groupby by borough\n",
    "    and hour.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    df['TIME']=pd.to_datetime(df['TIME'])\n",
    "    df['HOUR'] = df['TIME'].dt.hour\n",
    "    bor_hour = df.groupby(['BOROUGH', 'HOUR']).size()    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return bor_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-faa3c5768fdc05c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 8.2\n",
    "##### 8.2.1\n",
    "\n",
    "Plot a bar graph for each borough showing the number of accidents for each hour of the day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-cf78df4c32eb7f7c",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "bor_hour = ex_8_1(df).to_frame().reset_index()\n",
    "bor_hour = bor_hour.rename(columns={0:\"count\"})\n",
    "chart = sns.FacetGrid(bor_hour, col='BOROUGH', margin_titles=True, col_wrap=3, aspect=2, row_order=df['BOROUGH'].unique)\n",
    "chart.map(sns.barplot, 'HOUR', 'count',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb03b8b83ea90208",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 8.2.2\n",
    "\n",
    "Which hours have the most accidents for each borough?\n",
    "\n",
    "**Hint:** You can use ```sns.FacetGrid``` to create a grid of plots with the hourly data of each borough.\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> We can see that in all the boroughs the accident count is highest from approximately 2 - 6PM. But in Manhattan and the Bronx, you can see that there is not as much of a relative increase during these hours as in Brooklyn or Queens. Additionally, Staten Island has the lowest overall number of accidents.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5fb1df47b08de6f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "20_min"
    ]
   },
   "source": [
    "### Exercise 9 (hard)\n",
    "\n",
    "Using `contrib_df`, find which 6 factors cause the most accidents. It is important that you avoid double counting the contributing factors of a single accident.\n",
    "\n",
    "**Hint:** You can use the [**`pd.melt()`**](https://pandas.pydata.org/docs/reference/api/pandas.melt.html) function to take a subset of `df` and convert it from [wide format to narrow format](https://en.wikipedia.org/wiki/Wide_and_narrow_data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98f4ca4b8b9f6037",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_9(df):\n",
    "    \"\"\"\n",
    "    Finds which 6 factors cause the most accidents, without \n",
    "    double counting the contributing factors of a single accident.\n",
    "    \n",
    "    Arguments:\n",
    "    `contrib_df`: A pandas DataFrame.\n",
    "    \n",
    "    Outputs:\n",
    "    `factors_most_acc`: A pandas DataFrame. It has only 6 elements, which are,\n",
    "    sorted in descending order, the contributing factors with the most accidents.\n",
    "    The column with the actual numbers is named `index`.    \n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    contrib_fact_cols = ['CONTRIBUTING FACTOR VEHICLE 1','CONTRIBUTING FACTOR VEHICLE 2','CONTRIBUTING FACTOR VEHICLE 3','CONTRIBUTING FACTOR VEHICLE 4','CONTRIBUTING FACTOR VEHICLE 5']\n",
    "    contrib_df = pd.melt(df.reset_index(), id_vars=\"index\", value_vars=contrib_fact_cols).dropna()\n",
    "    contrib_df.head(10)\n",
    "    \n",
    "    # We drop the \"variable\" column - we don't need it here\n",
    "    factors_most_acc = contrib_df.drop(columns=\"variable\").copy()\n",
    "\n",
    "    # This is the crucial step - removing duplicates so that we don't count the same accident:factor pair more than once\n",
    "    factors_most_acc = factors_most_acc.drop_duplicates()\n",
    "\n",
    "    # Good old groupby, etc.\n",
    "    factors_most_acc = factors_most_acc.groupby(\"value\").count()\n",
    "    factors_most_acc = factors_most_acc.sort_values(by=\"index\", ascending=False).head(6)\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return factors_most_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cf540a533b618241",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "20_min"
    ]
   },
   "source": [
    "### Exercise 10 (hard)\n",
    "\n",
    "Which 10 vehicle type-borough pairs are most involved in accidents? Avoid double counting the types of vehicles involved in a single accident. You can apply a similar approach to the one used in the previous exercise using `pd.melt()`.\n",
    "\n",
    "**Hint:** You may want to include `BOROUGH` as one of your `id_vars` (the other being `index`) in `pd.melt()`. Including `BOROUGH` in your final `.groupby()` is also a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4088733a6a07c9a3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_10(df):\n",
    "    \"\"\"\n",
    "    Finds the 10 borough:vehicle type pairs with more accidents, without \n",
    "    double counting the vehicle types of a single accident.\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame.\n",
    "    \n",
    "    Outputs:\n",
    "    `vehi_most_acc`: A pandas DataFrame. It has only 10 elements, which are,\n",
    "    sorted in descending order, the borough-vehicle pairs with the most accidents.\n",
    "    The column with the actual numbers is named `index`\n",
    "    \"\"\"\n",
    "\n",
    "    vehi_cols = ['VEHICLE TYPE CODE 1','VEHICLE TYPE CODE 2','VEHICLE TYPE CODE 3','VEHICLE TYPE CODE 4','VEHICLE TYPE CODE 5']\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    vehi_df = pd.melt(df.reset_index(), id_vars=[\"index\",\"BOROUGH\"], value_vars=vehi_cols).dropna()\n",
    "\n",
    "    # We drop the \"variable\" column - we don't need it here\n",
    "    vehi_most_acc = vehi_df.drop(columns=\"variable\").copy()\n",
    "\n",
    "    # This is the crucial step - removing duplicates so that we don't count\n",
    "    # the same accident:borough:vehicle_type triplet more than once\n",
    "    vehi_most_acc = vehi_most_acc.drop_duplicates()\n",
    "    vehi_most_acc\n",
    "\n",
    "    # Good old groupby, etc.\n",
    "    vehi_most_acc = vehi_most_acc.groupby([\"BOROUGH\",\"value\"]).count()\n",
    "    vehi_most_acc = vehi_most_acc.sort_values(by=\"index\", ascending=False).head(10)\n",
    "    \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return vehi_most_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6185ec3a6e0f2096",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": true
    },
    "tags": [
     "10_min"
    ]
   },
   "source": [
    "### Exercise 11\n",
    "\n",
    "In a 2018 [interview](https://www.nytimes.com/2019/01/01/nyregion/traffic-deaths-decrease-nyc.html) with The New York Times, New York's mayor de Blasio stated that \"*Vision Zero is clearly working*\". That year, the number of deaths in traffic accidents in NYC dropped to a historically low 202. Yet, as reported by [am New York Metro](https://www.amny.com/news/vision-zero-de-blasio-1-30707464/), the number of fatalities has increased by 30% in the first quarter of 2019 compared to the previous year and the number of pedestrians and cyclists injured has not seen any improvement.\n",
    "\n",
    "Which of the following BEST describes how you would use the provided data to understand what went wrong in the first quarter of 2019? Please explain the reasons for your choice.\n",
    "\n",
    "<ul>\n",
    "A. Consider the accidents of the first quarter of 2019. Then, check for the most common causes of accidents where pedestrians and cyclists were involved. Give a recommendation based solely on this information.<br>\n",
    "B. Create a pair of heat maps of the accidents involving injured/killed pedestrians and cyclists in the first quarter of 2018 and 2019. Compare these two to see if there is any change in the concentration of accidents. In critical areas, study the type of factors involved in the accidents. Give a recommendation to visit these areas to study the problem further.<br>\n",
    "C. The provided data is insufficient to improve our understanding of the situation.<br>\n",
    "D. None of the above. (If you choose this, please elaborate on what you would do instead.)<br>\n",
    "</ul>\n",
    "\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.** You get half the points if you chose B, and the other half for giving a convincing argument for it. If you chose D, you will get full points if you give a convincing argument. Here are some thoughts:\n",
    "\n",
    "* A is not viable as we are not taking into account possible changes the Vision Zero program implemented after the first quarter of 2018.\n",
    "\n",
    "* B is more nuanced as it is trying to understand first what changes might had happened after the first quarter of 2018. Then, it concentrates in important areas of the city and then suggests a visit to improve understanding of the situation. \n",
    "\n",
    "* C is not correct. Even though the provided data may not completely answer what went wrong in the first quarter of 2019, it may provide hints of where to look and avoid unnecessary work.\n",
    "\n",
    "* D may or may not be valid, depending on what you wrote. There is not always a single approach for diagnosing problems like this one.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b0eb22fc9f454341",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "30_min"
    ]
   },
   "source": [
    "### Exercise 12 (hard)\n",
    "\n",
    "#### 12.1\n",
    "\n",
    "Calculate the number of deaths caused by each type of vehicle.\n",
    "\n",
    "**Hint 1:** As an example of how to compute vehicle involvement in deaths, suppose two people died in an accident where 5 vehicles were involved, and 4 are PASSENGER VEHICLE and 1 is a SPORT UTILITY/STATION WAGON. Then we would add two deaths to both the PASSENGER VEHICLE and SPORT UTILITY/STATION WAGON types.)\n",
    "\n",
    "**Hint 2:** You will need to use `pd.melt()` and proceed as in the previous exercises to avoid double-counting the types of vehicles (i.e. you should remove duplicate \"accident ID - vehicle type\" pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-84b57a3cbf3d976f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ex_12(df):\n",
    "    \"\"\"\n",
    "    Calculate total killed per vehicle type and plot the result\n",
    "    as a bar graph\n",
    "    \n",
    "    Arguments:\n",
    "    `df`: A pandas DataFrame.    \n",
    "    \n",
    "    Outputs:\n",
    "    `result`: A pandas DataFrame. Its index should be the vehicle type. Its only\n",
    "    column should be `TOTAL KILLED`\n",
    "    \"\"\"\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # This code computes the TOTAL KILLED column and removes accidents with no deaths \n",
    "    df[\"TOTAL KILLED\"] = df[['NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST KILLED']].apply(sum, axis=1)\n",
    "    rows_with_deaths = df[\"TOTAL KILLED\"]>0\n",
    "    df = df[rows_with_deaths]\n",
    "    \n",
    "    # Keeping only relevant columns\n",
    "    keep_columns = ['VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2', 'VEHICLE TYPE CODE 3',\n",
    "           'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5','TOTAL KILLED']\n",
    "    df = df[keep_columns].reset_index()\n",
    "    \n",
    "    # Melting and cleaning\n",
    "    df = pd.melt(df, id_vars=[\"index\", \"TOTAL KILLED\"], value_vars=keep_columns.remove(\"TOTAL KILLED\"))\n",
    "    df = df.drop(columns=\"variable\")\n",
    "    df = df.dropna(subset=[\"value\"])\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.groupby(\"value\")[[\"TOTAL KILLED\"]].sum()\n",
    "    result = df.sort_values(by=\"TOTAL KILLED\", ascending=False)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e6546c1b98dfc66",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 12.2\n",
    "##### 12.2.1\n",
    "\n",
    "Plot a bar chart for the top 5 vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-168b88cb6833db0d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "ex_12(df).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-40a05f4c5f6975fc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "##### 12.2.2\n",
    "\n",
    "Which vehicles are most often involved in deaths, and by how much more than the others?\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "**Answer.**\n",
    "\n",
    "You get full points if you included some interpretation like this:\n",
    "\n",
    "> It appears that `Station Wagon/Sport Utility Vehicle` and `Sedan` cause the most deaths. The former causes 4 times as many deaths as the other vehicles, and the latter causes 3 times as many deaths as the other vehicles. ```SPORT UTILITY / STATION WAGON``` is essentially the same as ```Station Wagon/Sport Utility Vehicle```, so these should be considered as one.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4bb6f46c8a40208",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Testing cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8603b4cdee9ac4a7",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 2\n",
    "assert type(ex_2(df)) == type(pd.Series([9,1,2])), \"Ex. 2 - Your output isn't a pandas Series. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert ex_2(df).loc[\"2018-10\"] == 13336, \"Ex. 2 - Wrong output! Try using the .size() aggregation function with your .groupby().\"\n",
    "print(\"Exercise 2.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0446147196bd9bf1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex 4\n",
    "assert type(ex_4(df)) == type(pd.Series([9,1,2])), \"Ex. 4 - Your output isn't a pandas Series. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert ex_4(df).loc[13] == 14224, \"Ex. 4 - Wrong output! Try using the .size() aggregation function with your .groupby().\"\n",
    "print(\"Exercise 4.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4caba3f3fb6ed65e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 6\n",
    "assert type(ex_6(df)) == type(pd.Series([9,1,2])), \"Ex. 6 - Your output isn't a pandas Series. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert max(ex_6(df)) == 37886, \"Ex. 6 - Your results don't match ours! Remember that you can use the .size() aggregation function to count the number of elements in a groupby group.\"\n",
    "print(\"Exercise 6.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d0d5b19c5e858b5b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 7.1\n",
    "assert type(ex_7_1(df)) == type(pd.Series([9,1,2])), \"Ex. 7.1 - Your output isn't a pandas Series. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert max(ex_7_1(df)) == 76253, \"Ex. 7.1 - Your results don't match ours! Remember that you can use the .size() aggregation function to count the number of elements in a groupby group.\"\n",
    "print(\"Exercise 7.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-15083640059ae00c",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 7.3\n",
    "with open('data/borough_data.json') as f:\n",
    "    borough_data=json.load(f)\n",
    "borough_data\n",
    "e73 = ex_7_3(df, borough_data)\n",
    "assert \"accidents_per_sq_mi\" in e73.columns, \"Ex. 7.3 - You didn't create an 'accidents_per_sq_mi' in your DataFrame!\"\n",
    "assert round(min(e73[\"accidents_per_sq_mi\"])) == 149, \"Ex. 7.3 - Your output doesn't match ours! Remember that you need to divide the number of accidents in each of the five boroughs by the respective areas in square miles.\"\n",
    "print(\"Exercise 7.3 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3a8314b522d587d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 8.1\n",
    "assert type(ex_8_1(df)) == type(pd.Series([9,1,2])), \"Ex. 9 - Your output isn't a pandas Series. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert ex_8_1(df).max() == 5701, \"Ex. 8.1 - Your numbers don't match ours. If you haven't already, you can try using .size() as your aggregation function.\"\n",
    "print(\"Exercise 8.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f7e925a7d3176181",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 9\n",
    "assert type(ex_9(df)) == type(pd.Series([9,1,2]).to_frame()), \"Ex. 9 - Your output isn't a pandas DataFrame. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert len(ex_9(df)) == 6, \"Ex. 9 - Your output doesn't have six elements. Did you forget to use .head(6)?\"\n",
    "assert int(ex_9(df).sum()) == 316248, \"Ex. 9 - Your numbers don't match ours. Are you sure you sorted your Series in descending order? If you haven't already, you can try using .count() as your aggregation function.\"\n",
    "print(\"Exercise 9 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d8b6e5f8bc04083",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 10\n",
    "assert type(ex_10(df)) == type(pd.Series([9,1,2]).to_frame()), \"Ex. 10 - Your output isn't a pandas DataFrame. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert len(ex_10(df)[\"index\"]) == 10, \"Ex. 10 - Your output doesn't have 10 elements. Did you forget to use .head(10)?\"\n",
    "assert ex_10(df)[\"index\"].sum() == 229882, \"Ex. 10 - Your numbers don't match ours. Are you sure you sorted your Series in descending order? If you haven't already, you can try using .count() as your aggregation function.\"\n",
    "print(\"Exercise 10 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7ca8cbd13d9c22d1",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ex. 12\n",
    "e12 = ex_12(df)\n",
    "assert type(e12) == type(pd.Series([9,1,2]).to_frame()), \"Ex. 12 - Your output isn't a pandas DataFrame. If you use .groupby(), it outputs a Series by default.\"\n",
    "assert int(e12.loc[\"Bike\"]) == 19, \"Ex. 12 - Your output doesn't match ours! Remember that you need to remove the duplicate pairs and use the .sum() aggregation function in your groupby.\"\n",
    "print(\"Exercise 12.1 looks correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b34aebdab696006",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Attribution\n",
    "\n",
    "\"Vehicle Collisions in NYC 2015-Present\", New York Police Department, [NYC Open Data terms of use](https://opendata.cityofnewyork.us/overview/#termsofuse), https://www.kaggle.com/nypd/vehicle-collisions\n",
    "\n",
    "\"Boroughs of New York City\", Creative Commons Attribution-ShareAlike License, https://en.wikipedia.org/wiki/Boroughs_of_New_York_City"
   ]
  }
 ],
 "metadata": {
  "c1_recart": "6.0.0-SNAPSHOT-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
